5_attention
[INFO: train_w_local_context.py:  126]: Initializing train dataset
[INFO: train_w_local_context.py:  128]: Initializing val dataset
[INFO: train_w_local_context.py:  136]: There are 42.0625 iterations per epoch
[INFO: train_w_local_context.py:  166]: Here is the generator:
[INFO: train_w_local_context.py:  167]: TrajectoryGenerator(
  (encoder): EncoderAtt(
    (self_attention): MultiheadAttention(
      (out_proj): Linear(in_features=64, out_features=64, bias=True)
    )
    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)
  )
  (decoder): Decoder(
    (decoder): LSTM(64, 128)
    (pool_net): PoolHiddenNet(
      (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)
      (mlp_pre_pool): Sequential(
        (0): Linear(in_features=192, out_features=512, bias=True)
        (1): ReLU()
        (2): Linear(in_features=512, out_features=1024, bias=True)
        (3): ReLU()
      )
    )
    (mlp): Sequential(
      (0): Linear(in_features=1152, out_features=1024, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1024, out_features=128, bias=True)
      (3): ReLU()
    )
    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)
    (hidden2pos): Linear(in_features=128, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1024, bias=True)
      (3): ReLU()
    )
  )
  (mlp_decoder_context): Sequential(
    (0): Linear(in_features=1178, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=128, bias=True)
    (3): ReLU()
  )
)
[INFO: train_w_local_context.py:  182]: Here is the discriminator:
[INFO: train_w_local_context.py:  183]: TrajectoryDiscriminator(
  (encoder): EncoderAtt(
    (self_attention): MultiheadAttention(
      (out_proj): Linear(in_features=64, out_features=64, bias=True)
    )
    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train_w_local_context.py:  202]: Restoring from checkpoint ../checkpoints_zara/checkpoint_with_model.pt
[INFO: train_w_local_context.py:  246]: Starting epoch 126
Traceback (most recent call last):
  File "scripts/train_w_local_context.py", line 594, in <module>
    main(args)
  File "scripts/train_w_local_context.py", line 259, in main
    optimizer_d, processed_local_info)
  File "scripts/train_w_local_context.py", line 385, in discriminator_step
    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end, all_local_info = processed_local_info)
  File "/home/dansj/.conda/envs/5_attention/lib/python3.5/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dansj/CS236-Project/methods/5_attention/Code/sgan/models_w_local_context.py", line 557, in forward
    local_context = all_local_info.extract_batch(pix_end_pos.cpu().numpy())
  File "/home/dansj/CS236-Project/methods/5_attention/Code/vgg/lclgph.py", line 99, in extract_batch
    feat = self.points_to_crop(g_cells)
  File "/home/dansj/CS236-Project/methods/5_attention/Code/vgg/lclgph.py", line 41, in points_to_crop
    feat = self.vgg(feat)
  File "/home/dansj/.conda/envs/5_attention/lib/python3.5/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dansj/CS236-Project/methods/5_attention/Code/vgg/networks.py", line 80, in forward
    h = F.relu(self.conv1_2(h), inplace=True)
  File "/home/dansj/.conda/envs/5_attention/lib/python3.5/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dansj/.conda/envs/5_attention/lib/python3.5/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/dansj/.conda/envs/5_attention/lib/python3.5/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 8.19 GiB (GPU 0; 11.17 GiB total capacity; 2.14 GiB already allocated; 8.18 GiB free; 548.60 MiB cached)
